---
title: 'Examining Corresponding, Ranked Peaks'
author: 'Robert M Flight'
date: '`r Sys.time()`'
output:
  pdf_document:
    extra_dependencies: ['longtable', 'float']
urlcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Purpose

Hunter has this idea that we can improve sample-to-sample normalization using relative ranking of peaks based on their intensity ranks.
So this is my attempting to figure out if that will work.

## Setup

```{r setup_packages}
library(dplyr)
library(visualizationQualityControl)
library(smirfeTools)
library(ggplot2)
library(rlang)
theme_set(cowplot::theme_cowplot())
```

## Load Data

Data we have is **all** the peaks from each sample, along with their ranks, along with the assigned and voted on peaks across samples.
The peaks and their IDs (`Sample_Peak`) should match up between the two data sets.

```{r load_data}
all_peaks = readRDS("testing_stuff/lung_all_peaks.rds")
voted_data = readRDS("testing_stuff/lung_voted_all.rds")
imf_data = extract_imf_emf_data(voted_data, by = "IMF")
```

```{r functions}
calc_rank = function(values){
  rank(values, ties.method = "random") / length(values)
}

calc_median_rank = function(peak_df, rank_column = fractional_rank){
  dplyr::group_by(peak_df, imf) %>%
    dplyr::summarise(median_rank = median({{rank_column}}))
}
```

## Analysis

```{r peak_correspondence}
imf_peaks = imf_data$peaks
peak_counts = apply(imf_peaks, 1, function(.x){sum(!is.na(.x))})
n_sample = ncol(imf_peaks)

peak_frac = peak_counts / n_sample
peak_frac_df = data.frame(imf = rownames(imf_peaks), fraction = peak_frac,
                          stringsAsFactors = FALSE)

imf_2_peak = purrr::map_df(rownames(imf_peaks), function(in_row){
  data.frame(imf = in_row,
             Sample_Peak = as.vector(imf_peaks[in_row, ]),
             stringsAsFactors = FALSE)
})
imf_2_peak = dplyr::filter(imf_2_peak, !is.na(Sample_Peak))
imf_2_peak = dplyr::left_join(imf_2_peak, peak_frac_df, by = "imf")
use_imf = peak_frac >= 0.9
use_peaks = imf_peaks[use_imf, ]
```

```{r peak_ranks}
split_peaks = split(all_peaks, all_peaks$Sample)
all_peaks = purrr::map_df(split_peaks, function(in_peaks){
  in_peaks$fractional_rank = calc_rank(in_peaks$Height)
  in_peaks
})
n_peak_sample = dplyr::group_by(all_peaks, Sample) %>%
  dplyr::summarise(n_peak = dplyr::n())
all_peaks = dplyr::left_join(all_peaks, n_peak_sample, by = "Sample")

imf_ranks = dplyr::left_join(imf_2_peak, all_peaks[, c("Sample_Peak", "fractional_rank", "n_peak")], by = "Sample_Peak")

imf_median_rank = imf_ranks %>% 
  dplyr::group_by(imf) %>%
  dplyr::summarise(median_org = median(fractional_rank)) %>%
  dplyr::left_join(., peak_frac_df, by = "imf")
```

Let's see if the data that Hunter would want to use even exists!

```{r check_fractions_vs_rank}
ggplot(imf_median_rank, aes(x = median_org, y = fraction)) + geom_point(alpha = 0.5) +
  geom_vline(xintercept = 0.5, color = "red") +
  geom_hline(yintercept = 0.8, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

OK, I previously messed up the rank within a sample, in that a lower number previously meant it was more highly ranked.
**Now it is right!**
A higher number in a sample means it is more highly ranked in the sample.

The next step then is to look at the peaks that appear in a decent number of samples, say **10** (so a fraction >= 0.05), and let's slice it down to things that are in the range of 0.5 median ranked across samples, using a range of 0.4 to 0.6.

```{r plot_points_inrange}
ggplot(imf_median_rank, aes(x = median_org, y = fraction)) + geom_point(alpha = 0.5) +
  xlim(0.4, 0.6) + 
  geom_hline(yintercept = 0.05, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

```{r trim_data}
trim_ranks = dplyr::filter(imf_median_rank, dplyr::between(median_org, 0.6, 0.8),
                           fraction >= 0.055)

use_peaks = dplyr::filter(imf_2_peak, imf %in% trim_ranks$imf) %>%
  dplyr::left_join(., all_peaks, by = "Sample_Peak")

ggplot(use_peaks, aes(x = n_peak, y = fractional_rank)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks$n_peak, use_peaks$fractional_rank)
```

OK, there is definitely a positive correlation between the fractional rank of a peak and the number of peaks in the sample.
Now, can we correct it and make the correlation value lower?

Let's try a simple example.

```{r example_rank_correction}
tmp_data = rnorm(1000)
tmp_ranks = calc_rank(tmp_data)

rank_df = data.frame(value = tmp_data, org_rank = tmp_ranks)
rank_df2 = rank_df[order(rank_df$org_rank), ]
rank_df2 = rank_df2[200:1000, ]
rank_df2$new_rank = calc_rank(rank_df2$value)

ggplot(rank_df2, aes(new_rank, org_rank)) + geom_point() + geom_abline(slope = 0.8, intercept = 0.2,  color = "red")
```

Interestingly, we can create a linear model **$rank_{org} = 0.2 + 0.8 \times rank_{new}$)** that relates the two ranks.

So, this corresponds to doing the following:

$$rank_{org} = (1 - \frac{P_{sample}}{P_{max}})+ \frac{P_{sample}}{P_{max}} \times rank_{new}$$

Let's see if we can get this to work on our actual data.

```{r correct_data}
imf_ranks = dplyr::filter(imf_ranks, fraction >= 0.057) %>%
  dplyr::left_join(., imf_median_rank, by = "imf")
imf_rank_corrected = dplyr::mutate(imf_ranks, max_peaks = max(n_peak),
                                   model1 = 1 - (n_peak / max_peaks),
                                   model2 = n_peak / max_peaks,
                                   lc_rank = model1 + (model2 * fractional_rank))

lc_median = imf_rank_corrected %>% dplyr::group_by(imf) %>%
  dplyr::summarise(median_lc = median(lc_rank)) %>%
  dplyr::left_join(., imf_rank_corrected, by = "imf")

ggplot(dplyr::filter(lc_median, dplyr::between(median_lc, 0.65, 0.75)), aes(x = n_peak, y = lc_rank)) +
  geom_point() +
  geom_smooth(method = "lm")

cor.test(~ lc_rank + n_peak, data = dplyr::filter(lc_median, dplyr::between(median_lc, 0.65, 0.75)))
```

So, we did the correction, and then we calculated new medians, and made sure to evaluate based on those new median values.
**And it appears to be an over-correction.**

This is probably because not **all** the peaks are lost on the low end, so the correction isn't exactly right.

An alternative method is to use the fitted linear model, and the ratio of the current predicted value to the maximum predicted value.
I think that should work to transform our correlation to something closer to 0.
**However, this takes advantage of the fact that we have 200 samples to do the correction with ...**, which is not realistic.

```{r correct_try2}
tmp_data = as.data.frame(dplyr::filter(lc_median, dplyr::between(median_org, 0.65, 0.75)))
fit_npeak = lm(fractional_rank ~ n_peak, data = tmp_data)
rank_lookup = data.frame(n_peak = tmp_data$n_peak, fit_rank = fit_npeak$fitted.values) %>% unique(.)
rank_lookup = rank_lookup[!duplicated(rank_lookup$n_peak), ]
rank_lookup = rank_lookup[order(rank_lookup$n_peak), ]
rank_lookup = dplyr::mutate(rank_lookup, rank_ratio = fit_rank / max(fit_rank))
lc_median = dplyr::left_join(lc_median, rank_lookup, by = "n_peak")
corrected_ratiofit = dplyr::mutate(lc_median, ratiofit_rank = fractional_rank / rank_ratio)

lc_median = corrected_ratiofit %>%
  dplyr::group_by(imf) %>%
  dplyr::summarise(median_rf = median(ratiofit_rank)) %>%
  dplyr::left_join(., corrected_ratiofit, by = "imf")
ggplot(dplyr::filter(lc_median, dplyr::between(median_rf, 0.65, 0.75)), aes(x = n_peak, y = median_rf)) + geom_point() +
  geom_smooth(method = "lm")
cor.test(~ n_peak + median_rf, data = dplyr::filter(lc_median, dplyr::between(median_rf, 0.65, 0.75)))
```

**And the correlation is gone!** The 95% CI on the test is now: -0.02 - 0.031.


## Verify By Simulation

So I wonder if we can verify this is what happens using a simulation?
If we take say 200 samples, with 4500 peaks, and then let up to 0.6 of the mostly lower intensity ones get dropped, do we see the same phenomena?
The nice thing is, because we are talking about ranks (essentially quantiles) they are actually distribution agnostic.

```{r simulate_dropout}
set.seed(1234)
library(fakeDataWithError)
base_distribution = rnorm(4500, mean = 10, sd = 1)
rep_data = add_uniform_noise(200, base_distribution, 0.5)
rep_data = matrix(base_distribution, nrow = length(base_distribution), ncol = 200, byrow = FALSE)
drop_prob = rnorm(200, mean = 2500, sd = 800)
low_prob = drop_prob < 1800
drop_prob[low_prob] = drop_prob[low_prob] + 1800
hi_prob = drop_prob > 4500
drop_prob[hi_prob] = 4500
colnames(rep_data) = paste0("s", seq(1, ncol(rep_data)))
rownames(rep_data) = paste0("f", seq(1, nrow(rep_data)))
drop_prob = floor(drop_prob)
```

My strategy for this is going to be:
  * Coin toss for each peak
  * Probability of being discarded in the coin toss is **directly** weighted by it's relative rank
  * Continue removing points until we reach number of points to remove (based on `drop_prob` above)
  * This should allow low intensity points to be kept at random and also remove random points above a rank of 0.5

```{r remove_points}
removed_points = purrr::map_df(seq(1, ncol(rep_data)), function(in_col){
  #message(in_col)
  tmp_data = rep_data[, in_col]
  tmp_rank = calc_rank(tmp_data)
  names(tmp_rank) = names(tmp_data)
  
  get_loc = 1
  if (drop_prob[in_col] > length(tmp_data)/2) {
    keep_or_drop = rep(TRUE, length(tmp_rank))
    while (sum(keep_or_drop) > drop_prob[in_col]) {
      if (get_loc > length(tmp_rank)) {
        get_loc = 1
      }
      if (keep_or_drop[get_loc]) {
        keep_or_drop[get_loc] = sample(c(TRUE, FALSE), 1, prob = c(tmp_rank[get_loc], 1 - tmp_rank[get_loc]))
      }
      get_loc = get_loc + 1
    }
  } else {
    keep_or_drop = rep(FALSE, length(tmp_rank))
    while (sum(keep_or_drop) <= drop_prob[in_col]) {
      
      if (get_loc > length(tmp_rank)) {
        get_loc = 1
      }
      if (!(keep_or_drop[get_loc])) {
        keep_or_drop[get_loc] = sample(c(TRUE, FALSE), 1, prob = c(tmp_rank[get_loc], 1 - tmp_rank[get_loc]))
      }
       
      get_loc = get_loc + 1
    #message(sum(keep_or_drop))
    }
  }
  
  out_data = data.frame(Peak = names(tmp_rank),
                        Sample = colnames(rep_data)[in_col],
                        Height = tmp_data,
                        org_rank = tmp_rank,
                        stringsAsFactors = FALSE)
  out_data$Sample_Peak = paste0(out_data$Sample, "_", out_data$Peak)
  out_data = out_data[keep_or_drop, ]
  out_data$new_rank = calc_rank(out_data$Height)
  out_data
})
```

OK, and now we can check things out!

```{r check_removed}
removed_npeak = dplyr::group_by(removed_points, Sample) %>%
  dplyr::summarize(n_peak = dplyr::n())
removed_points = dplyr::left_join(removed_points, removed_npeak, by = "Sample")
n_insample = dplyr::group_by(removed_points, Peak) %>%
  dplyr::summarise(n_sample = dplyr::n(),
                   median_rank = median(new_rank))
keep_removed = dplyr::filter(n_insample, n_sample >= 10)
```

```{r plot_removed, dev = 'png'}
removed_keep = dplyr::left_join(keep_removed, removed_points, by = "Peak")
ggplot(dplyr::filter(removed_keep, dplyr::between(median_rank, 0.65, 0.75)), aes(x = n_peak, y = new_rank)) + geom_point() +
  geom_smooth(method = "lm")
```

**Cool!!** It matches at least somewhat what we were seeing previously.

### Correction of Simulated Data

Now we can try applying the same correction we derived above on our simulated data.

```{r correction_simulated, dev = 'png'}
corrected_keep = dplyr::mutate(removed_keep, max_peaks = max(n_peak),
                             model1 = 1 - (n_peak / max_peaks),
                             model2 = n_peak / max_peaks)
corrected_keep = dplyr::mutate(corrected_keep, lc_rank = model1 + (model2 * new_rank))

removed_keep = corrected_keep %>%
  dplyr::group_by(Peak) %>%
  dplyr::summarise(median_lc = median(lc_rank)) %>%
  dplyr::left_join(., corrected_keep, by = "Peak")
ggplot(dplyr::filter(removed_keep, dplyr::between(median_lc, 0.65, 0.75)), aes(x = n_peak, y = lc_rank)) + geom_point() + geom_smooth(method = "lm")
cor.test(~ n_peak + lc_rank, dplyr::filter(removed_keep, dplyr::between(median_lc, 0.65, 0.75)))
```

Yeah, still not working.

What if we try to find the ratio of $$\frac{n_{peak}}{max_{peak}}$$ first?

```{r correction_simualted2, dev = 'png'}
removed_keep = dplyr::mutate(removed_keep, ratio_peaks = n_peak / max_peaks,
                             ratio_rank = new_rank / org_rank)
ggplot(dplyr::filter(removed_keep, dplyr::between(median_rank, 0.65, 0.75)), aes(x = ratio_peaks, y = ratio_rank)) + geom_point() + geom_smooth(method = "lm")

ratio_fit = lm(ratio_rank ~ ratio_peaks, data = dplyr::filter(removed_keep, dplyr::between(median_rank, 0.65, 0.75)))
rr_corrected_keep = dplyr::mutate(removed_keep, rr_rank = new_rank / (0.61 + 0.42*ratio_peaks))

removed_keep = rr_corrected_keep %>%
  dplyr::group_by(Peak) %>%
  dplyr::summarise(rr_median = median(rr_rank)) %>%
  dplyr::left_join(., rr_corrected_keep, by = "Peak")

ggplot(dplyr::filter(removed_keep, dplyr::between(rr_median, 0.65, 0.75)), aes(x = n_peak, y = rr_rank)) + geom_point() + geom_smooth(method = "lm")
cor.test(~ n_peak + rr_rank, dplyr::filter(removed_keep, dplyr::between(rr_median, 0.65, 0.75)))
```

Good thing Hunter realized I wasn't plotting what I thought I was, **because this last solution doesn't work**.
**Crud**.

So right now the best option is the one that involves the fit to the whole data, I think.
Let's see if that works here.

```{r simulation_fit_ratio}
tmp_sim = dplyr::filter(removed_keep, dplyr::between(median_rank, 0.65, 0.75))
tmp_fit = lm(new_rank ~ n_peak, data = tmp_sim)
sim_lookup = data.frame(n_peak = tmp_sim$n_peak, fit_rank = tmp_fit$fitted.values) %>% unique(.)
sim_lookup = sim_lookup[!duplicated(sim_lookup$n_peak), ]
sim_lookup = dplyr::mutate(sim_lookup, rank_ratio = fit_rank / max(fit_rank))
removed_keep = dplyr::left_join(removed_keep, sim_lookup, by = "n_peak")

corrected_lookup = dplyr::mutate(removed_keep, ll_rank = new_rank / rank_ratio)
removed_keep = corrected_lookup %>%
  dplyr::group_by(Peak) %>%
  dplyr::summarise(ll_median = median(ll_rank)) %>%
  dplyr::left_join(., corrected_lookup)

ggplot(dplyr::filter(removed_keep, dplyr::between(ll_median, 0.65, 0.75)), aes(x = n_peak, y = ll_rank)) + 
  geom_point() + geom_smooth(method = "lm")
```

Nope, that doesn't even work on the simulated data.
That doesn't mean it's not a bad option.
It also might be related to the structure of our simulated data compared to the real data.


## How Does This Affect Normalization?

We are going to calculate some metrics after we do normalization a couple of different ways.

### Metrics

1. Relative Standard Deviation of peak intensities
1. P-values of not-cancer vs cancer

### Normalization Methods

1. Median peak intensity (**median**)
1. Peak ranked at 0.5 in a sample (**n50**)
1. Peak ranked at 0.7 in a sample (**n70**)
1. Peak ranked most consistently at 0.5 / 0.7 (**close50/70**)

### Do It!

```{r raw_rsd}
lc_median_intensity = dplyr::left_join(lc_median, all_peaks[, c("Sample_Peak", "Height", "Sample")], by = "Sample_Peak")
lc_median_intensity = dplyr::mutate(lc_median_intensity,
                                    type = dplyr::case_when(
                                      grepl("Npos.*", Sample, ignore.case = TRUE) ~ "non-cancer",
                                      TRUE ~ "cancer"
                                    ))
raw_rsd = lc_median_intensity %>% 
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height),
                   sd = sd(Height),
                   rsd = sd / mean,
                   which = "raw")
```

```{r median_normalization}
lung_json = readRDS("testing_stuff/lung_all_json.rds")
lung_norm = purrr::map_df(lung_json, function(in_json){
  data.frame(Value = in_json$peak$other_info$median_intensity,
             Sample = gsub(".zip$", "", in_json$zip$file),
             stringsAsFactors = FALSE)
})

mediannorm_rsd = dplyr::left_join(lc_median_intensity, lung_norm, by = "Sample") %>%
  dplyr::mutate(Height_mediannorm = Height / Value) %>%
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height_mediannorm),
                   sd = sd(Height_mediannorm),
                   rsd = sd / mean,
                   which = "median")
```

```{r rank_50_70}
lc_median_intensity = dplyr::mutate(lc_median_intensity, diff_50 = abs(ratiofit_rank - 0.5),
                                    diff_70 = abs(ratiofit_rank - 0.7))
norm_50 = lc_median_intensity %>% 
  dplyr::group_by(Sample) %>%
  dplyr::arrange(diff_50) %>%
  dplyr::slice(1) %>%
  dplyr::select(Height, Sample) %>%
  dplyr::mutate(Value = Height)
norm_50_rsd = dplyr::left_join(lc_median_intensity, norm_50[, c("Sample", "Value")], by = "Sample") %>%
  dplyr::mutate(Height_norm50 = Height / Value) %>%
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height_norm50),
                   sd = sd(Height_norm50),
                   rsd = sd / mean,
                   which = "n50")

norm_70 = lc_median_intensity %>% 
  dplyr::group_by(Sample) %>%
  dplyr::arrange(diff_70) %>%
  dplyr::slice(1) %>%
  dplyr::select(Height, Sample) %>%
  dplyr::mutate(Value = Height)
norm_70_rsd = dplyr::left_join(lc_median_intensity, norm_70[, c("Sample", "Value")], by = "Sample") %>%
  dplyr::mutate(Height_norm70 = Height / Value) %>%
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height_norm70),
                   sd = sd(Height_norm70),
                   rsd = sd / mean,
                   which = "n70")
```

```{r most_consistent_5070}
n_imf = lc_median_intensity %>%
  dplyr::group_by(imf) %>%
  dplyr::summarise(n_sample = dplyr::n())

use_imf = dplyr::filter(n_imf, n_sample >= 150)
lc_use_imf = dplyr::left_join(use_imf, lc_median_intensity, by = "imf")
most_close50 = lc_use_imf %>%
  dplyr::group_by(imf) %>%
  dplyr::summarise(sum_50 = sum(diff_50)) %>%
  dplyr::arrange(sum_50) %>%
  dplyr::slice(1)
norm_close50 = dplyr::left_join(most_close50, lc_median_intensity, by = "imf") %>%
  dplyr::select(Height, Sample) %>%
  dplyr::mutate(Value = Height)
norm_close50_rsd = dplyr::left_join(norm_close50[, c("Sample", "Value")], lc_median_intensity, by = "Sample") %>%
  dplyr::mutate(Height_close50 = Height / Value) %>%
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height_close50),
                   sd = sd(Height_close50),
                   rsd = sd /mean,
                   which = "close50")

most_close70 = lc_use_imf %>%
  dplyr::group_by(imf) %>%
  dplyr::summarise(sum_70 = sum(diff_70)) %>%
  dplyr::arrange(sum_70) %>%
  dplyr::slice(1)
norm_close70 = dplyr::left_join(most_close70, lc_median_intensity, by = "imf") %>%
  dplyr::select(Height, Sample) %>%
  dplyr::mutate(Value = Height)
norm_close70_rsd = dplyr::left_join(norm_close70[, c("Sample", "Value")], lc_median_intensity, by = "Sample") %>%
  dplyr::mutate(Height_close70 = Height / Value) %>%
  dplyr::group_by(imf, type) %>%
  dplyr::summarise(mean = mean(Height_close70),
                   sd = sd(Height_close70),
                   rsd = sd /mean,
                   which = "close70")
```

### Compare RSDs

```{r compare_rsd}
all_rsd = rbind(norm_50_rsd, norm_70_rsd, norm_close50_rsd, norm_close70_rsd, mediannorm_rsd, raw_rsd)
all_rsd$which_type = paste0(all_rsd$type, "_", all_rsd$which)
library(ggridges)
ggplot(all_rsd, aes(x = rsd, y = which_type)) + geom_density_ridges() +
  coord_cartesian(xlim = c(0, 1.5)) + geom_vline(xintercept = 0.33, color = "red") +
  labs(caption = "Density RSDs using each type of normalization, with a red line at 0.33, \nthe mode for non-cancer median, n50 and n70")
```

```{r table_of_medians}
knitr::kable(dplyr::group_by(all_rsd, which_type) %>%
  dplyr::summarise(median_rsd = median(rsd, na.rm = TRUE)), digits = 3)

```

### But Wait ...

Is the ratio of the median to the max intensity affected the same way?
If it is, that implies that we could simply adjust the median value using this same correction, and then still correct by the median.
I bring this up because I don't think we will find many peaks that will be ranked near the middle of the pack.

But that also begs the question, do we need to use peaks for normalization that are near the center, or can we use anything that is **consistently** ranked the same (after above correction) across samples??

## Hunter Comments on Correction

((max_peaks/2) - missing_peaks)/(max_peaks - missing_peaks) 

where missing peaks = max_peaks - curr_peaks

## Truly Evaluating Solutions

To truly evaluate what we've done, we need to make sure of two things:

  1. We are looking at correlation with peaks that have their rank adjusted, and then re-evaluated for median rank across samples
  1. We look at some actual metrics. These include:
    * The variance of normalized peaks using one of these corrections vs none vs median intensity normalization
    * The change in p-values of cancer vs non-cancer using the various methods to correct