---
title: 'Examining Corresponding, Ranked Peaks'
author: 'Robert M Flight'
date: '`r Sys.time()`'
output:
  pdf_document:
    extra_dependencies: ['longtable', 'float']
urlcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Purpose

Hunter has this idea that we can improve sample-to-sample normalization using relative ranking of peaks based on their intensity ranks.
So this is me trying to figure out if that will work.

## Setup

```{r setup_packages}
library(dplyr)
library(visualizationQualityControl)
library(smirfeTools)
library(ggplot2)
theme_set(cowplot::theme_cowplot())
```

## Load Data

Data we have is **all** the peaks from each sample, along with their ranks, along with the assigned and voted on peaks across samples.
The peaks and their IDs (`Sample_Peak`) should match up between the two data sets.

```{r load_data}
all_peaks = readRDS("testing_stuff/lung_all_peaks.rds")
voted_data = readRDS("testing_stuff/lung_voted_all.rds")
imf_data = extract_imf_emf_data(voted_data, by = "IMF")
```

## Analysis

```{r peak_correspondence}
calc_rank = function(values){
  rank(values, ties.method = "random") / length(values)
}

imf_peaks = imf_data$peaks
peak_counts = apply(imf_peaks, 1, function(.x){sum(!is.na(.x))})
n_sample = ncol(imf_peaks)

peak_frac = peak_counts / n_sample
peak_frac_df = data.frame(imf = rownames(imf_peaks), fraction = peak_frac,
                          stringsAsFactors = FALSE)

imf_2_peak = purrr::map_df(rownames(imf_peaks), function(in_row){
  data.frame(imf = in_row,
             Sample_Peak = as.vector(imf_peaks[in_row, ]),
             stringsAsFactors = FALSE)
})
imf_2_peak = dplyr::filter(imf_2_peak, !is.na(Sample_Peak))
imf_2_peak = dplyr::left_join(imf_2_peak, peak_frac_df, by = "imf")
use_imf = peak_frac >= 0.9
use_peaks = imf_peaks[use_imf, ]
```

```{r peak_ranks}
split_peaks = split(all_peaks, all_peaks$Sample)
all_peaks = purrr::map_df(split_peaks, function(in_peaks){
  in_peaks$fractional_rank = calc_rank(in_peaks$Height)
  in_peaks
})
n_peak_sample = dplyr::group_by(all_peaks, Sample) %>%
  dplyr::summarise(n_peak = dplyr::n())
all_peaks = dplyr::left_join(all_peaks, n_peak_sample, by = "Sample")

imf_ranks = dplyr::left_join(imf_2_peak, all_peaks[, c("Sample_Peak", "fractional_rank", "n_peak")], by = "Sample_Peak")

imf_median_rank = dplyr::group_by(imf_ranks, imf) %>%
  dplyr::summarize(median_rank = median(fractional_rank))
imf_median_rank = dplyr::left_join(imf_median_rank, peak_frac_df, by = "imf")
```

Let's see if the data that Hunter would want to use even exists!

```{r check_fractions_vs_rank}
ggplot(imf_median_rank, aes(x = median_rank, y = fraction)) + geom_point(alpha = 0.5) +
  geom_vline(xintercept = 0.5, color = "red") +
  geom_hline(yintercept = 0.8, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

OK, I previously messed up the rank within a sample, in that a lower number previously meant it was more highly ranked.
**Now it is right!**
A higher number in a sample means it is more highly ranked in the sample.

But we are going to try anyway.
The next step then is to look at the peaks that appear in a decent number of samples, say **10** (so a fraction >= 0.05), and let's slice it down to things that are in the range of 0.5 median ranked across samples, using a range of 0.4 to 0.6.

```{r plot_points_inrange}
ggplot(imf_median_rank, aes(x = median_rank, y = fraction)) + geom_point(alpha = 0.5) +
  xlim(0.4, 0.6) + 
  geom_hline(yintercept = 0.05, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

```{r trim_data}
trim_ranks = dplyr::filter(imf_median_rank, dplyr::between(median_rank, 0.4, 0.6),
                           fraction >= 0.055)

use_peaks = dplyr::filter(imf_2_peak, imf %in% trim_ranks$imf) %>%
  dplyr::left_join(., all_peaks, by = "Sample_Peak")

ggplot(use_peaks, aes(x = n_peak, y = fractional_rank)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks$n_peak, use_peaks$fractional_rank)
```

OK, there is definitely a positive correlation between the fractional rank of a peak and the number of peaks in the sample.
Now, can we correct it and make the correlation value lower?

```{r correct_data}
max_peaks = max(use_peaks$n_peak)

use_peaks2 = dplyr::select(use_peaks, imf, Sample_Peak, fraction, rank, n_peak, fractional_rank) %>%
  dplyr::mutate(peak_max = n_peak / max_peaks)
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank = fractional_rank / (peak_max))

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank)
```

OK, this doesn't work, and I think I know why.
It's because the the maximum value of `fractional_rank` is **not** 1.
If the maximum values **was** 1, then this simple correction would work.

An alternative method is to use the fitted linear model, and the ratio of the current predicted value to the maximum predicted value.
I think that should work to transform our correlation to something closer to 0.

```{r correct_try2}
fit_npeak = lm(fractional_rank ~ n_peak, data = use_peaks2)
fitted_ranks = fit_npeak$fitted.values
use_peaks2$rank_ratio = fitted_ranks / max(fitted_ranks)
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank2 = fractional_rank / rank_ratio)

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank2)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank2)
```

**And the correlation is gone!** The 95% CI on the test is now: -0.02 - 0.02.

```{r fits}
fit_npeak

out_fit = data.frame(n_peak = use_peaks2$n_peak, fractional_rank = use_peaks2$fractional_rank, fitted_rank = fit_npeak$fitted.values)
write.table(out_fit, file = "testing_stuff/linear_fit.csv", sep = ",", row.names = FALSE, col.names = TRUE)
```

There is actually a sigmoidal fit, which we can see if we use a `glm` model.

```{r sigmoid_fit}
gam_fit = mgcv::gam(fractional_rank ~ s(n_peak, bs = "cs"), data = use_peaks2)

out_gam = data.frame(n_peak = use_peaks2$n_peak, fractional_rank = use_peaks2$fractional_rank, fitted_rank = gam_fit$fitted.values)
write.table(out_gam, file = "testing_stuff/sigmoid_fit.csv", sep = ",", row.names = FALSE,
            col.names = TRUE)
```

Hunter thinks we can do it if we adjust it again slightly, using `peak_max / 2` as the factor.

```{r correct_try3}
use_peaks2 = use_peaks2 %>%
  dplyr::mutate(rank_ratio3 = n_peak / (max_peaks / 2))
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank3 = fractional_rank / rank_ratio3)

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank3)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank3)
```

Nope, that doesn't work.
So the linear model fit looks like the best bet, even if it seems to pull up instead of down ...

## Verify By Simulation

So I wonder if we can verify this is what happens using a simulation?
If we take say 200 samples, with 4500 peaks, and then let up to 1/2 of the mostly lower intensity ones get dropped, do we see the same phenomena?
The nice thing is, because we are talking about ranks (essentially quantiles) they are actually distribution agnostic.

```{r simulate_dropout}
set.seed(1234)
library(fakeDataWithError)
base_distribution = rnorm(4500, mean = 10, sd = 1)
rep_data = add_uniform_noise(200, base_distribution, 0.5)
rep_data = matrix(base_distribution, nrow = length(base_distribution), ncol = 200, byrow = FALSE)
drop_prob = rnorm(200, mean = 2500, sd = 800)
low_prob = drop_prob < 1800
drop_prob[low_prob] = drop_prob[low_prob] + 1800
hi_prob = drop_prob > 4500
drop_prob[hi_prob] = 4500
colnames(rep_data) = paste0("s", seq(1, ncol(rep_data)))
rownames(rep_data) = paste0("f", seq(1, nrow(rep_data)))
drop_prob = floor(drop_prob)
```

My strategy for this is going to be:
  * Coin toss
  * Probability of Remove / Keep is going to start at 0.9 / 0.1 and decrease to 0.5 / 0.5 as calculated rank approaches 0.5
  * Continue removing points until we reach number of points to remove (based on `drop_prob` above)
  * This should allow low intensity points to be kept at random and also remove random points above a rank of 0.5

```{r remove_points}
removed_points = purrr::map_df(seq(1, ncol(rep_data)), function(in_col){
  #message(in_col)
  tmp_data = rep_data[, in_col]
  tmp_rank = calc_rank(tmp_data)
  names(tmp_rank) = names(tmp_data)
  
  get_loc = 1
  if (drop_prob[in_col] > length(tmp_data)/2) {
    keep_or_drop = rep(TRUE, length(tmp_rank))
    while (sum(keep_or_drop) > drop_prob[in_col]) {
      if (get_loc > length(tmp_rank)) {
        get_loc = 1
      }
      if (keep_or_drop[get_loc]) {
        keep_or_drop[get_loc] = sample(c(TRUE, FALSE), 1, prob = c(tmp_rank[get_loc], 1 - tmp_rank[get_loc]))
      }
      get_loc = get_loc + 1
    }
  } else {
    keep_or_drop = rep(FALSE, length(tmp_rank))
    while (sum(keep_or_drop) <= drop_prob[in_col]) {
      
      if (get_loc > length(tmp_rank)) {
        get_loc = 1
      }
      if (!(keep_or_drop[get_loc])) {
        keep_or_drop[get_loc] = sample(c(TRUE, FALSE), 1, prob = c(tmp_rank[get_loc], 1 - tmp_rank[get_loc]))
      }
       
      get_loc = get_loc + 1
    #message(sum(keep_or_drop))
    }
  }
  
  out_data = data.frame(Peak = names(tmp_rank),
                        Sample = colnames(rep_data)[in_col],
                        Height = tmp_data,
                        org_rank = tmp_rank,
                        stringsAsFactors = FALSE)
  out_data$Sample_Peak = paste0(out_data$Sample, "_", out_data$Peak)
  out_data = out_data[keep_or_drop, ]
  out_data$new_rank = calc_rank(out_data$Height)
  out_data
})
```

OK, and now we can check things out!

```{r check_removed}
removed_npeak = dplyr::group_by(removed_points, Sample) %>%
  dplyr::summarize(n_peak = dplyr::n())
removed_points = dplyr::left_join(removed_points, removed_npeak, by = "Sample")
n_insample = dplyr::group_by(removed_points, Peak) %>%
  dplyr::summarise(n_sample = dplyr::n(),
                   median_rank = median(new_rank))
keep_removed = dplyr::filter(n_insample, n_sample >= 10,
                             dplyr::between(median_rank, 0.4, 0.6))
```

```{r plot_removed}
removed_keep = dplyr::filter(removed_points, Peak %in% keep_removed$Peak)
ggplot(removed_keep, aes(x = n_peak, y = new_rank)) + geom_point() +
  geom_smooth(method = "lm")
```

Cool, I had the removal of points incorrect, and was preferentially removing points on the high end.
Now this is correct, and matches what we've been seeing in our samples above.

## How Does This Affect Normalization?

OK, we can correct the ranking of peaks within a sample.
So how does this affect normalization?

If we correct the ranking of **all** peaks in **all** samples, then we have a much better idea of **which** peaks actually have ranks close to **0.5** in a majority of samples, if they exist.

We should be using peaks with a median rank close to **0.5** to normalize samples.
We can test this by doing a p-value comparison, similar to what we've done previously (code which I need to find).

### But Wait ...

Is the ratio of the median to the max intensity affected the same way?
If it is, that implies that we could simply adjust the median value using this same correction, and then still correct by the median.
I bring this up because I don't think we will find many peaks that will be ranked near the middle of the pack.

But that also begs the question, do we need to use peaks for normalization that are near the center, or can we use anything that is **consistently** ranked the same (after above correction) across samples??

## Hunter Comments on Correction

((max_peaks/2) - missing_peaks)/(max_peaks - missing_peaks) 

where missing peaks = max_peaks - curr_peaks