---
title: 'Examining Corresponding, Ranked Peaks'
author: 'Robert M Flight'
date: '`r Sys.time()`'
output:
  pdf_document:
    extra_dependencies: ['longtable', 'float']
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Purpose

Hunter has this idea that we can improve sample-to-sample normalization using relative ranking of peaks based on their intensity ranks.
So this is me trying to figure out if that will work.

## Setup

```{r setup_packages}
library(dplyr)
library(visualizationQualityControl)
library(smirfeTools)
library(ggplot2)
theme_set(cowplot::theme_cowplot())
```

## Load Data

Data we have is **all** the peaks from each sample, along with their ranks, along with the assigned and voted on peaks across samples.
The peaks and their IDs (`Sample_Peak`) should match up between the two data sets.

```{r load_data}
all_peaks = readRDS("testing_stuff/lung_all_peaks.rds")
voted_data = readRDS("testing_stuff/lung_voted_all.rds")
imf_data = extract_imf_emf_data(voted_data, by = "IMF")
```

## Analysis

```{r peak_correspondence}
imf_peaks = imf_data$peaks
peak_counts = apply(imf_peaks, 1, function(.x){sum(!is.na(.x))})
n_sample = ncol(imf_peaks)

peak_frac = peak_counts / n_sample
peak_frac_df = data.frame(imf = rownames(imf_peaks), fraction = peak_frac,
                          stringsAsFactors = FALSE)

imf_2_peak = purrr::map_df(rownames(imf_peaks), function(in_row){
  data.frame(imf = in_row,
             Sample_Peak = as.vector(imf_peaks[in_row, ]),
             stringsAsFactors = FALSE)
})
imf_2_peak = dplyr::filter(imf_2_peak, !is.na(Sample_Peak))
imf_2_peak = dplyr::left_join(imf_2_peak, peak_frac_df, by = "imf")
use_imf = peak_frac >= 0.9
use_peaks = imf_peaks[use_imf, ]
```

```{r peak_ranks}
n_peak_sample = dplyr::group_by(all_peaks, Sample) %>%
  dplyr::summarise(n_peak = dplyr::n())
all_peaks = dplyr::left_join(all_peaks, n_peak_sample, by = "Sample")
all_peaks$fractional_rank = 1 - (all_peaks$rank / all_peaks$n_peak)

imf_ranks = dplyr::left_join(imf_2_peak, all_peaks[, c("Sample_Peak", "fractional_rank", "n_peak")], by = "Sample_Peak")

imf_median_rank = dplyr::group_by(imf_ranks, imf) %>%
  dplyr::summarize(median_rank = median(fractional_rank))
imf_median_rank = dplyr::left_join(imf_median_rank, peak_frac_df, by = "imf")
```

Let's see if the data that Hunter would want to use even exists!

```{r check_fractions_vs_rank}
ggplot(imf_median_rank, aes(x = median_rank, y = fraction)) + geom_point(alpha = 0.5) +
  geom_vline(xintercept = 0.5, color = "red") +
  geom_hline(yintercept = 0.8, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

OK, I previously messed up the rank within a sample, in that a lower number previously meant it was more highly ranked.
**Now it is right!**
A higher number in a sample means it is more highly ranked in the sample.

But we are going to try anyway.
The next step then is to look at the peaks that appear in a decent number of samples, say **10** (so a fraction >= 0.05), and let's slice it down to things that are in the range of 0.5 median ranked across samples, using a range of 0.4 to 0.6.

```{r plot_points_inrange}
ggplot(imf_median_rank, aes(x = median_rank, y = fraction)) + geom_point(alpha = 0.5) +
  xlim(0.4, 0.6) + 
  geom_hline(yintercept = 0.05, color = "red") +
  labs(subtitle = "Median Rank across Samples vs Fraction of Total Samples",
       x = "Median Rank of Peak", y = "Fraction of Samples Present")
```

```{r trim_data}
trim_ranks = dplyr::filter(imf_median_rank, dplyr::between(median_rank, 0.4, 0.6),
                           fraction >= 0.055)

use_peaks = dplyr::filter(imf_2_peak, imf %in% trim_ranks$imf) %>%
  dplyr::left_join(., all_peaks, by = "Sample_Peak")

ggplot(use_peaks, aes(x = n_peak, y = fractional_rank)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks$n_peak, use_peaks$fractional_rank)
```

OK, there is definitely a positive correlation between the fractional rank of a peak and the number of peaks in the sample.
Now, can we correct it and make the correlation value lower?

```{r correct_data}
max_peaks = max(use_peaks$n_peak)

use_peaks2 = dplyr::select(use_peaks, imf, Sample_Peak, fraction, rank, n_peak, fractional_rank) %>%
  dplyr::mutate(peak_max = n_peak / max_peaks)
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank = fractional_rank / (peak_max))

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank)
```

OK, this doesn't work, and I think I know why.
It's because the the maximum value of `fractional_rank` is **not** 1.
If the maximum values **was** 1, then this simple correction would work.

An alternative method is to use the fitted linear model, and the ratio of the current predicted value to the maximum predicted value.
I think that should work to transform our correlation to something closer to 0.

```{r correct_try2}
fit_npeak = lm(fractional_rank ~ n_peak, data = use_peaks2)
fitted_ranks = fit_npeak$fitted.values
use_peaks2$rank_ratio = fitted_ranks / max(fitted_ranks)
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank2 = fractional_rank / rank_ratio)

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank2)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank2)
```

**And the correlation is gone!** The 95% CI on the test is now: -0.02 - 0.02.

Hunter thinks we can do it if we adjust it again slightly, using `max(fitted_ranks)/2` as the factor.

```{r correct_try3}
use_peaks2$rank_ratio3 = fitted_ranks / (max(fitted_ranks) / 2)
use_peaks2 = dplyr::mutate(use_peaks2, corrected_rank3 = fractional_rank / rank_ratio3)

ggplot(use_peaks2, aes(x = n_peak, y = corrected_rank3)) + geom_point(alpha = 0.5) +
  geom_smooth(method = "lm")
cor.test(use_peaks2$n_peak, use_peaks2$corrected_rank3)
```

OK, neat, that also seems to work, and is much easier to implement.
It does seem to pull things **down** instead of **up** however.
From that perspective I'm not quite sure which one is actually better.

```{r compare_corrections}
ggplot(use_peaks2, aes(x = corrected_rank2, y = corrected_rank3)) + geom_point() +
  geom_abline(slope = 0.5, color = "red")
```

But overall they are correcting the fractional ranks the same way, which makes sense because we are just shifting the peaks either up or down.

## How Does This Affect Normalization?

OK, we can correct the ranking of peaks within a sample.
So how does this affect normalization?

If we correct the ranking of **all** peaks in **all** samples, then we have a much better idea of **which** peaks actually have ranks close to **0.5** in a majority of samples, if they exist.

We should be using peaks with a median rank close to **0.5** to normalize samples.
We can test this by doing a p-value comparison, similar to what we've done previously (code which I need to find).

### But Wait ...

Is the ratio of the median to the max intensity affected the same way?
If it is, that implies that we could simply adjust the median value using this same correction, and then still correct by the median.
I bring this up because I don't think we will find many peaks that will be ranked near the middle of the pack.

But that also begs the question, do we need to use peaks for normalization that are near the center, or can we use anything that is **consistently** ranked the same (after above correction) across samples??

```{r check_median_ratio}
json_data = readRDS("testing_stuff/lung_all_json.rds")
median_intensities = purrr::map_df(json_data, function(in_json){
  data.frame(Sample = gsub(".zip$", "", in_json$zip$file),
             median = in_json$peak$other_info$median_intensity,
             stringsAsFactors = FALSE)
})

match_median = purrr::map_df(seq(1, nrow(median_intensities)), function(in_row){
  tmp_data = median_intensities[in_row, ]
  match_sample_median = dplyr::filter(all_peaks, Sample %in% tmp_data$Sample)
  use_peak = which.min(abs(tmp_data$median - match_sample_median$Height))
  cbind(tmp_data, match_sample_median[use_peak, c("Height", "Sample_Peak", "fractional_rank", "n_peak")])
})
max_peak = dplyr::group_by(all_peaks, Sample) %>%
  dplyr::summarise(max_intensity = max(Height))
median_intensities = dplyr::left_join(median_intensities, max_peak, by = "Sample")
median_intensities = dplyr::mutate(median_intensities, fraction = median / max_intensity)
median_intensities = dplyr::left_join(median_intensities, unique(all_peaks[, c("Sample", "n_peak")]), by = "Sample")
```

